{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47906b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f2c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/Clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49eb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coord'] = df['lat'] * df['long']\n",
    "df.drop(['zipcode','lat','long'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5827655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99f7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbc1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76214473 0.73950338 0.75503581 0.73725033 0.74748808]\n",
      "-34218451592.19468\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42b9cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "y_test_scaled = scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56130eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77164736 0.73953127 0.75505613 0.73833722 0.74748873]\n",
      "-0.2500526377738525\n"
     ]
    }
   ],
   "source": [
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39db5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "974ff36c",
   "metadata": {},
   "source": [
    "to log X_data can't use anything with a zero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00dad4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_log = np.log(y_train) #['log_price']\n",
    "df_price_log_test = np.log(y_test)\n",
    "\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "y_scaled_log_price_test = scaler.transform(df_price_log_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e37041fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scaled_log_price = PolynomialFeatures(degree = 2)\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "#cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train,scoring = 'neg_mean_squared_error', cv=5)\n",
    "#print(cv_results)\n",
    "#cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train,scoring = 'neg_mean_squared_error' cv=5,  scoring='neg_mean_squared_error'))\n",
    "#print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14fc24b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-21eacf4f0b45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# calculate predictions on training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_hat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_scaled_log_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_hat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_scaled_log_price\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#compare MSE for the predicted training and test values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# calculate predictions on training and test sets\n",
    "y_hat_train = model_scaled_log_price.predict(X_train_scaled)\n",
    "y_hat_test = model_scaled_log_price.predict(X_test_scaled)\n",
    "\n",
    "#compare MSE for the predicted training and test values \n",
    "train_mse = mean_squared_error(y_scaled_log_price_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_scaled_log_price_test, y_hat_test)\n",
    "\n",
    "\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac7d66",
   "metadata": {},
   "source": [
    "[0.82096421 0.81406076 0.80113155 0.81273929 0.81141737]\n",
    "-0.18784958406146018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3af4921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21242 entries, 0 to 21418\n",
      "Data columns (total 46 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   price             21242 non-null  float64\n",
      " 1   bedrooms          21242 non-null  float64\n",
      " 2   bathrooms         21242 non-null  float64\n",
      " 3   sqft_living       21242 non-null  float64\n",
      " 4   sqft_lot          21242 non-null  float64\n",
      " 5   floors            21242 non-null  float64\n",
      " 6   waterfront        21242 non-null  int64  \n",
      " 7   view              21242 non-null  float64\n",
      " 8   condition         21242 non-null  float64\n",
      " 9   grade             21242 non-null  float64\n",
      " 10  sqft_above        21242 non-null  float64\n",
      " 11  basement          21242 non-null  int64  \n",
      " 12  yr_built          21242 non-null  float64\n",
      " 13  yr_renovated      21242 non-null  float64\n",
      " 14  lat               21242 non-null  float64\n",
      " 15  long              21242 non-null  float64\n",
      " 16  sqft_living15     21242 non-null  float64\n",
      " 17  sqft_lot15        21242 non-null  float64\n",
      " 18  Auburn            21242 non-null  float64\n",
      " 19  Bellevue          21242 non-null  float64\n",
      " 20  Black_diamond     21242 non-null  float64\n",
      " 21  Bothell           21242 non-null  float64\n",
      " 22  Duball            21242 non-null  float64\n",
      " 23  Enumclaw          21242 non-null  float64\n",
      " 24  Fall city         21242 non-null  float64\n",
      " 25  Federal_way       21242 non-null  float64\n",
      " 26  Issaquah          21242 non-null  float64\n",
      " 27  Kenmore           21242 non-null  float64\n",
      " 28  Kent              21242 non-null  float64\n",
      " 29  Kirkland          21242 non-null  float64\n",
      " 30  Maple Valley      21242 non-null  float64\n",
      " 31  Medina            21242 non-null  float64\n",
      " 32  Mercer Island     21242 non-null  float64\n",
      " 33  North Bend        21242 non-null  float64\n",
      " 34  Renton            21242 non-null  float64\n",
      " 35  Sammamish         21242 non-null  float64\n",
      " 36  Seattle           21242 non-null  float64\n",
      " 37  Snoqualmie        21242 non-null  float64\n",
      " 38  Woodinville       21242 non-null  float64\n",
      " 39  sqft_living_diff  21242 non-null  float64\n",
      " 40  sqft_lot_diff     21242 non-null  float64\n",
      " 41  year              21242 non-null  float64\n",
      " 42  x0_fall           21242 non-null  float64\n",
      " 43  x0_spring         21242 non-null  float64\n",
      " 44  x0_summer         21242 non-null  float64\n",
      " 45  x0_winter         21242 non-null  float64\n",
      "dtypes: float64(44), int64(2)\n",
      "memory usage: 7.6 MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55041c8a",
   "metadata": {},
   "source": [
    "TESTING SPLIT IN 2 LOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0690ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] < 9]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f1faf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6710213  0.69522063 0.69685286 0.67026612 0.67125703]\n",
      "-12418445846.383966\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80a91ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14addb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67105391 0.69522054 0.6968378  0.67025889 0.67188672]\n",
      "-0.3182915573487553\n"
     ]
    }
   ],
   "source": [
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "527ffe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c303ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72413614 0.73556896 0.73611268 0.7182319  0.71958568]\n",
      "-0.273083365597513\n"
     ]
    }
   ],
   "source": [
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a134b78",
   "metadata": {},
   "source": [
    "LOWER SCORES OVERALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4df610",
   "metadata": {},
   "source": [
    "BASE LINE TEST SPLIT HIGH GRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea23c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] > 8]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9032d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67002878 0.74361246 0.71374602 0.71780729 0.73467976]\n",
      "-87905019629.65884\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ad7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17be0ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67001818 0.7435335  0.71368629 0.71781705 0.73469709]\n",
      "-0.2827557049702945\n"
     ]
    }
   ],
   "source": [
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83ecff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65bd971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75929759 0.79268187 0.77898245 0.79652485 0.7925555 ]\n",
      "-0.2152873002369923\n"
     ]
    }
   ],
   "source": [
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7ae9e6",
   "metadata": {},
   "source": [
    "ALSO LOWER THAN BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f57a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE TEST SPLIT TOTAL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6229fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 4]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8b9ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.16252223 -0.23691345 -1.18968868 -2.72165453 -0.08391814]\n",
      "-102665176004.01968\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73e64a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bd6e19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.43055136 -0.35574663 -0.84464161 -0.18815487 -0.85440257]\n",
      "-2.032741013638147\n"
     ]
    }
   ],
   "source": [
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9be16ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "431210e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.96362306 -0.20415776 -0.35827914  0.12283194 -0.83151438]\n",
      "-1.7911874337963627\n"
     ]
    }
   ],
   "source": [
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e73ed",
   "metadata": {},
   "source": [
    "ABSOLUTELY AWFUL, MOVING ON TOTAL SPLIT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3046b92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1017558  -0.09383212  0.01218587  0.2947682  -0.15125816]\n",
      "-15730181929.528858\n",
      "[-0.0515548  -0.12852018  0.0686805   0.28135763 -0.15125816]\n",
      "-0.9706072014433458\n",
      "[ 0.00654528  0.03470563  0.05697637  0.33165779 -0.01800349]\n",
      "-0.8811024040586428\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 5]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cb0048",
   "metadata": {},
   "source": [
    "NOPE, NEXT TOTAL 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73345316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40507473 0.47992618 0.5891721  0.48587888 0.4442934 ]\n",
      "-11192715571.033558\n",
      "[0.40491664 0.48010757 0.58663936 0.48314971 0.44430555]\n",
      "-0.5178637877412853\n",
      "[0.41142012 0.49345805 0.52719432 0.50918365 0.45828472]\n",
      "-0.5180817865919072\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 6]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b07983",
   "metadata": {},
   "source": [
    "BETTER THAN WITH GRADE 5, STILL AWFUL NEXT GRADE 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87f10885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59566218 0.65170218 0.60312171 0.64686288 0.64518194]\n",
      "-9085130924.355366\n",
      "[0.59568496 0.65179524 0.60310564 0.64684306 0.64531695]\n",
      "-0.3700053329492114\n",
      "[0.65043743 0.67976482 0.66168712 0.66891907 0.68454273]\n",
      "-0.3303041130732579\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 7]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408e45c",
   "metadata": {},
   "source": [
    "IMPRESSIVELY NOT COMPLETELY AWFUL, BUT STILL WORSE THAN THE BASELINE, NEXT GRADE IS 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ced19f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41851534 0.64937437 0.68650257 0.62731022 0.4769717 ]\n",
      "-17169212990.988342\n",
      "[0.59654091 0.64938381 0.68650648 0.62736316 0.65062065]\n",
      "-0.35469831835795146\n",
      "[0.67373546 0.69412132 0.73512368 0.69721706 0.71820701]\n",
      "-0.2952967348135324\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 8]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6c6426",
   "metadata": {},
   "source": [
    "MEH, NEXT GRADE 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54006fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67635033 0.67920265 0.65310378 0.68060787 0.64342831]\n",
      "-54720906616.684715\n",
      "[0.67634788 0.67959929 0.65311929 0.68064543 0.64352702]\n",
      "-0.3334295426468615\n",
      "[0.75289802 0.76764188 0.72168513 0.75085244 0.73085334]\n",
      "-0.2550178202230099\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 9|base_model['grade']==10]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e58074",
   "metadata": {},
   "source": [
    "NEXT GRADE 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87655df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70664125 0.63595264 0.58609086 0.69080137 0.67519263]\n",
      "-81951705787.6537\n",
      "[0.70600625 0.63623632 0.58608592 0.69046059 0.67492346]\n",
      "-0.3416971879699595\n",
      "[0.70769155 0.67106253 0.62331802 0.72571084 0.68145443]\n",
      "-0.3178679015885566\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 10]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f9780",
   "metadata": {},
   "source": [
    "IT'S GETTING WORSE NOW, NEXT GRADE 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27dbf59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.58337836  0.67017376 -1.69055276  0.24483817 -0.73546256]\n",
      "-226889880560.369\n",
      "[ 5.83707733e-01  6.68963365e-01 -1.80516963e+23  3.25189540e-01\n",
      " -1.29192803e+22]\n",
      "-2.6882725350643006e+22\n",
      "[ 4.86605798e-01  6.59135621e-01 -4.13464607e+22  5.57292627e-01\n",
      " -1.84285250e+22]\n",
      "-1.1364323299639647e+22\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 11]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa57dd",
   "metadata": {},
   "source": [
    "THAT\"S A NO FROM ME, NEXT GRADE 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed4ec0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.338245    0.30870341 -1.62182501 -9.64923553  0.34502945]\n",
      "-879307300674.428\n",
      "[ -4.59282677   0.30870341  -1.62182501 -10.6787304    0.34502945]\n",
      "-2.1180384284222145\n",
      "[-2.16909421  0.30053686 -0.26993142 -0.95680387  0.28382544]\n",
      "-1.2270162660735415\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 12]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e777877",
   "metadata": {},
   "source": [
    "NOPE FINAL CHANCE TO PROVE A SPLIT WORKS GRADE 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04149684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.0018192    0.94173119   0.94745276  -0.30019202          nan]\n",
      "-63164076740601.94\n",
      "[-7.27496615  0.67500802  0.03089859 -0.11987703         nan]\n",
      "-0.5869332533875065\n",
      "[-8.06788585  0.56908528  0.2798255   0.57974253         nan]\n",
      "-0.5235207426226826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py:682: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py:682: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_regression.py:682: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "base_model = df.copy()\n",
    "\n",
    "base_model = base_model.loc[base_model['grade'] == 13]\n",
    "\n",
    "X , y = base_model.drop(columns=['price']), base_model[['price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "\n",
    "# train_preds = model1.predict(X_train)\n",
    "# y_train == train_preds \n",
    "\n",
    "test_preds = model1.predict(X_test)\n",
    "\n",
    "cv_results = cross_val_score(model1, X_train, y_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean = np.mean(cross_val_score(model1, X, y, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean)\n",
    "#model1.score(y_test, test_preds)\n",
    "scaler = StandardScaler()\n",
    "# Calculate the standard deviation of the X_train dataset\n",
    "scaler.fit(X_train)\n",
    "# convert all values into their standard deviation equivalents.\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(y_train)\n",
    "y_train_scaled = scaler.transform(y_train)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "test_preds_scaled = model_scaled.predict(X_train_scaled)\n",
    "\n",
    "cv_results_scaled = cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5)\n",
    "print(cv_results_scaled)\n",
    "cv_results_mean_scaled = np.mean(cross_val_score(model_scaled, X_train_scaled, y_train_scaled, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled)\n",
    "#model_scaled.score(test_preds, y_test)\n",
    "df_price_log = np.log(y_train) #['log_price']\n",
    " \n",
    "scaler.fit(df_price_log)\n",
    "y_scaled_log_price_train = scaler.transform(df_price_log)\n",
    "\n",
    "model_scaled_log_price = LinearRegression()\n",
    "model_scaled_log_price.fit(X_train_scaled, y_scaled_log_price_train)\n",
    "\n",
    "# train_preds = model_scaled.predict(X_train)\n",
    "#test_preds = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "cv_results = cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5)\n",
    "print(cv_results)\n",
    "cv_results_mean_scaled_ylog = np.mean(cross_val_score(model_scaled_log_price, X_train_scaled, y_scaled_log_price_train, cv=5,  scoring='neg_mean_squared_error'))\n",
    "print(cv_results_mean_scaled_ylog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4f2c6",
   "metadata": {},
   "source": [
    "DIDN\"T THINK SO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
